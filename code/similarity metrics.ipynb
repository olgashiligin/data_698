{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading data\n",
    "df = pd.read_csv(\"masters/data.csv\")\n",
    "# df.head()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.groupby('is_duplicate',as_index = False,group_keys=False).apply(lambda s: s.sample(50000,replace=True,random_state = 123))\n",
    "df.shape\n",
    "df.groupby(\"is_duplicate\")['id'].count().plot.bar(color=\"grey\").set_title('Duplicate vs Unique Question Pairs', fontsize=15)\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "def clean(text, stem_words=True):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "\n",
    "    # Clean the text\n",
    "#     text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"What's\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "    text = re.sub(r\"china\", \"China\", text)\n",
    "    text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\"quora\", \"Quora\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"gps\", \"GPS\", text)\n",
    "    text = re.sub(r\"gst\", \"GST\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"the US\", \"America\", text)\n",
    "    text = re.sub(r\"Astrology\", \"astrology\", text)\n",
    "    text = re.sub(r\"Method\", \"method\", text)\n",
    "    text = re.sub(r\"Find\", \"find\", text) \n",
    "    text = re.sub(r\"banglore\", \"Banglore\", text)\n",
    "    text = re.sub(r\" J K \", \" JK \", text)\n",
    "    # remove comma between numbers, i.e. 15,000 -> 15000\n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    # indian dollar\n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word \"number\"\n",
    "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text)\n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "#     if remove_stop_words:\n",
    "#         text = text.split()\n",
    "#         text = [w for w in text if not w in stop_words]\n",
    "#         text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "#     if lem_words:\n",
    "#         text = text.split()\n",
    "#         lem = WordNetLemmatizer()\n",
    "#         lem_words = [lem.lemmatize(word) for word in text]\n",
    "#         text = \" \".join(lem_words)\n",
    "    return text\n",
    "    \n",
    "df['question1'] = df['question1'].apply(clean)\n",
    "df['question2'] = df['question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, qid1, qid2, question1, question2, is_duplicate]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing NULL values with space\n",
    "df = df.fillna('')\n",
    "df[df.isnull().any(1)]\n",
    "\n",
    "# checking missing values\n",
    "df[df.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (WMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# calculating Word Mover's Distance\n",
    "def wmd(q1, q2):\n",
    "#     splitting sentence on tokens\n",
    "    q1 = str(q1).lower().split()\n",
    "    q2 = str(q2).lower().split()\n",
    "# filtering stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    q1 = [w2v_model for w2v_model in q1 if w2v_model not in stop_words]\n",
    "    q2 = [w2v_model for w2v_model in q2 if w2v_model not in stop_words]\n",
    "    \n",
    "    return w2v_model.wmdistance(q1, q2)\n",
    "#     applying wmd()\n",
    "df['wmd'] = df.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing word2vec vectors to calculate normalized wmd\n",
    "w2v_model.init_sims(replace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing normalized WMD\n",
    "df['norm_wmd'] = df.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Olga/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating cosine similarity based on word2vec\n",
    "import numpy as np\n",
    "from scipy import spatial \n",
    "\n",
    "global_index2word_set = set(w2v_model.wv.index2word)\n",
    "\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "        if (n_words > 0):\n",
    "            feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "\n",
    "# Calculate similarity:\n",
    "\n",
    "def w2v_cosine (sentence1,sentence2,model, num_features, index2word_set):\n",
    "    vec1 = avg_feature_vector(sentence1, model, num_features, index2word_set)\n",
    "    vec2 = avg_feature_vector(sentence2, model, num_features, index2word_set)\n",
    "    sim =  1 - spatial.distance.cosine(vec1, vec2)\n",
    "    return sim\n",
    "\n",
    "def w2v_manh (sentence1,sentence2,model, num_features, index2word_set):\n",
    "    vec1 = avg_feature_vector(sentence1, model, num_features, index2word_set)\n",
    "    vec2 = avg_feature_vector(sentence2, model, num_features, index2word_set)\n",
    "    sim2 =  1 - spatial.distance.cityblock(vec1, vec2)\n",
    "    return sim2\n",
    "\n",
    "df['w2v_cosine'] = df.apply(lambda x: w2v_cosine(x['question1'], x['question2'], model=w2v_model, num_features=300,index2word_set = global_index2word_set), axis=1)\n",
    "\n",
    "df['w2v_Manhattan'] = df.apply(lambda x: w2v_manh(x['question1'], x['question2'], model=w2v_model, num_features=300,index2word_set = global_index2word_set), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>395648</td>\n",
       "      <td>494699</td>\n",
       "      <td>528639</td>\n",
       "      <td>does crow see from just one eye</td>\n",
       "      <td>how far can one see with the naked eye how is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>25054</td>\n",
       "      <td>46729</td>\n",
       "      <td>46730</td>\n",
       "      <td>how do i unblock fortiguard application control</td>\n",
       "      <td>how can i unblock torrents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>44749</td>\n",
       "      <td>80277</td>\n",
       "      <td>80278</td>\n",
       "      <td>how can i make money off bitcoin</td>\n",
       "      <td>can you make money with bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>28223</td>\n",
       "      <td>52353</td>\n",
       "      <td>52354</td>\n",
       "      <td>who is the head of immigration officer of mala...</td>\n",
       "      <td>how do avascular plants and vascular plants di...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>306380</td>\n",
       "      <td>429895</td>\n",
       "      <td>429896</td>\n",
       "      <td>what is ionizing radiation</td>\n",
       "      <td>can you feel ionizing radiation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "395627  395648  494699  528639   \n",
       "25052    25054   46729   46730   \n",
       "44746    44749   80277   80278   \n",
       "28221    28223   52353   52354   \n",
       "306360  306380  429895  429896   \n",
       "\n",
       "                                                question1  \\\n",
       "395627                    does crow see from just one eye   \n",
       "25052     how do i unblock fortiguard application control   \n",
       "44746                    how can i make money off bitcoin   \n",
       "28221   who is the head of immigration officer of mala...   \n",
       "306360                         what is ionizing radiation   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "395627  how far can one see with the naked eye how is ...             0   \n",
       "25052                          how can i unblock torrents             0   \n",
       "44746                     can you make money with bitcoin             0   \n",
       "28221   how do avascular plants and vascular plants di...             0   \n",
       "306360                    can you feel ionizing radiation             0   \n",
       "\n",
       "             wmd  norm_wmd  w2v_cosine  w2v_Manhattan  \n",
       "395627  0.656735  0.656735    0.007304      -1.356412  \n",
       "25052   0.899362  0.899362    0.112670      -2.680161  \n",
       "44746   0.000000  0.000000    0.272492       0.382274  \n",
       "28221   1.360078  1.360078    0.011833      -1.791117  \n",
       "306360  0.455592  0.455592    0.982493      -0.249461  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate       wmd  norm_wmd  w2v_cosine  w2v_Manhattan\n",
       "395627             0  0.656735  0.656735    0.007304      -1.356412\n",
       "25052              0  0.899362  0.899362    0.112670      -2.680161\n",
       "44746              0  0.000000  0.000000    0.272492       0.382274\n",
       "28221              0  1.360078  1.360078    0.011833      -1.791117\n",
       "306360             0  0.455592  0.455592    0.982493      -0.249461"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim = df.drop(['question1', 'question2', 'id', 'qid1', 'qid2'], axis=1)\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.5264714381739327\n",
      "XGBoost 0.7254857323366751\n",
      "RandomForest 0.7319713751974856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import scipy \n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "df_sim = df_sim.fillna(df_sim.median()).clip(-1e11,1e11)\n",
    "\n",
    "X = df_sim.drop(['is_duplicate'],axis=1)\n",
    "y = df_sim['is_duplicate']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append((\"LogisticRegression\",LogisticRegression()))\n",
    "models.append((\"XGBoost\", xgb.XGBClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    result = cross_val_score(model, X_train, y_train,  cv=3)\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70     15137\n",
      "           1       0.69      0.80      0.74     14863\n",
      "\n",
      "    accuracy                           0.72     30000\n",
      "   macro avg       0.73      0.72      0.72     30000\n",
      "weighted avg       0.73      0.72      0.72     30000\n",
      "\n",
      "0.7249194378352388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build XGboost model\n",
    "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
    "# making predictions\n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, xgb_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73     15137\n",
      "           1       0.72      0.78      0.75     14863\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.74      0.74      0.74     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n",
      "0.7421700079505744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build rf model\n",
    "rf_model = RandomForestClassifier(max_depth=50, n_estimators=80).fit(X_train, y_train) \n",
    "# making predictions\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, rf_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "class Sentence:\n",
    "\n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"“\", \"\").replace(\"”\",\"\")\n",
    "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
    "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def read_tsv(f):\n",
    "    freq = {}\n",
    "    with open(f) as tsv:\n",
    "        tsv_reader = csv.reader(tsv, delimiter=' ')\n",
    "        for row in tsv_reader:\n",
    "            freq[row[0]] = int(row[1])\n",
    "    return freq\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def del_princ_comp(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=123)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "faulty_shit = []\n",
    "\n",
    "def sif(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001):\n",
    "    total_freq = sum(freqs.values())\n",
    "    embeddings = []\n",
    "    for (sent1, sent2) in zip(sentences1, sentences2):\n",
    "        tokens1 = sent1.tokensk_without_stop if use_stoplist else sent1.tokens\n",
    "        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "        tokens1 = [token for token in tokens1 if token in model]\n",
    "        tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "        weights1 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens1]\n",
    "        weights2 = [a / (a + freqs.get(token, 0) / total_freq) for token in tokens2]\n",
    "\n",
    "        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
    "        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
    "\n",
    "        embeddings.append(embedding1)\n",
    "        embeddings.append(embedding2)\n",
    "\n",
    "    embeddings = del_princ_comp(np.array(embeddings))\n",
    "    sims = [cosine_similarity(embeddings[idx * 2].reshape(1, -1),\n",
    "                              embeddings[idx * 2 + 1].reshape(1, -1))[0][0]\n",
    "            for idx in range(int(len(embeddings) / 2))]\n",
    " \n",
    "    return sims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frenquencies = read_tsv(\"/Users/Olga/PycharmProjects/data/frequencies.txt\")\n",
    "sentences1 = [Sentence(s) for s in df['question1']]\n",
    "sentences2 = [Sentence(s) for s in df['question2']]\n",
    "sims = sif(sentences1, sentences2, model=w2v_model, freqs=frenquencies, use_stoplist=False, a=0.001)\n",
    "df['SIF'] = np.array(sims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "qid1             0\n",
       "qid2             0\n",
       "question1        0\n",
       "question2        0\n",
       "is_duplicate     0\n",
       "wmd              0\n",
       "norm_wmd         0\n",
       "w2v_cosine       0\n",
       "w2v_Manhattan    0\n",
       "SIF              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>395648</td>\n",
       "      <td>494699</td>\n",
       "      <td>528639</td>\n",
       "      <td>does crow see from just one eye</td>\n",
       "      <td>how far can one see with the naked eye how is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "      <td>0.400244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>25054</td>\n",
       "      <td>46729</td>\n",
       "      <td>46730</td>\n",
       "      <td>how do i unblock fortiguard application control</td>\n",
       "      <td>how can i unblock torrents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "      <td>0.622001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>44749</td>\n",
       "      <td>80277</td>\n",
       "      <td>80278</td>\n",
       "      <td>how can i make money off bitcoin</td>\n",
       "      <td>can you make money with bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>28223</td>\n",
       "      <td>52353</td>\n",
       "      <td>52354</td>\n",
       "      <td>who is the head of immigration officer of mala...</td>\n",
       "      <td>how do avascular plants and vascular plants di...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "      <td>-0.040175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>306380</td>\n",
       "      <td>429895</td>\n",
       "      <td>429896</td>\n",
       "      <td>what is ionizing radiation</td>\n",
       "      <td>can you feel ionizing radiation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "      <td>0.713251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "395627  395648  494699  528639   \n",
       "25052    25054   46729   46730   \n",
       "44746    44749   80277   80278   \n",
       "28221    28223   52353   52354   \n",
       "306360  306380  429895  429896   \n",
       "\n",
       "                                                question1  \\\n",
       "395627                    does crow see from just one eye   \n",
       "25052     how do i unblock fortiguard application control   \n",
       "44746                    how can i make money off bitcoin   \n",
       "28221   who is the head of immigration officer of mala...   \n",
       "306360                         what is ionizing radiation   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "395627  how far can one see with the naked eye how is ...             0   \n",
       "25052                          how can i unblock torrents             0   \n",
       "44746                     can you make money with bitcoin             0   \n",
       "28221   how do avascular plants and vascular plants di...             0   \n",
       "306360                    can you feel ionizing radiation             0   \n",
       "\n",
       "             wmd  norm_wmd  w2v_cosine  w2v_Manhattan       SIF  \n",
       "395627  0.656735  0.656735    0.007304      -1.356412  0.400244  \n",
       "25052   0.899362  0.899362    0.112670      -2.680161  0.622001  \n",
       "44746   0.000000  0.000000    0.272492       0.382274  0.594603  \n",
       "28221   1.360078  1.360078    0.011833      -1.791117 -0.040175  \n",
       "306360  0.455592  0.455592    0.982493      -0.249461  0.713251  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "      <td>0.400244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "      <td>0.622001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "      <td>-0.040175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "      <td>0.713251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate       wmd  norm_wmd  w2v_cosine  w2v_Manhattan       SIF\n",
       "395627             0  0.656735  0.656735    0.007304      -1.356412  0.400244\n",
       "25052              0  0.899362  0.899362    0.112670      -2.680161  0.622001\n",
       "44746              0  0.000000  0.000000    0.272492       0.382274  0.594603\n",
       "28221              0  1.360078  1.360078    0.011833      -1.791117 -0.040175\n",
       "306360             0  0.455592  0.455592    0.982493      -0.249461  0.713251"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim = df.drop(['question1', 'question2', 'id', 'qid1', 'qid2'], axis=1)\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.5276285816437841\n",
      "XGBoost 0.7281286064191445\n",
      "RandomForest 0.7436285400998877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import scipy \n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "df_sim = df_sim.fillna(df_sim.median()).clip(-1e11,1e11)\n",
    "\n",
    "X = df_sim.drop(['is_duplicate'],axis=1)\n",
    "y = df_sim['is_duplicate']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append((\"LogisticRegression\",LogisticRegression()))\n",
    "models.append((\"XGBoost\", xgb.XGBClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    result = cross_val_score(model, X_train, y_train,  cv=3)\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71     15137\n",
      "           1       0.70      0.81      0.75     14863\n",
      "\n",
      "    accuracy                           0.73     30000\n",
      "   macro avg       0.74      0.74      0.73     30000\n",
      "weighted avg       0.74      0.73      0.73     30000\n",
      "\n",
      "0.7350394620251678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build XGboost model\n",
    "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
    "# making predictions\n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, xgb_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74     15137\n",
      "           1       0.73      0.81      0.77     14863\n",
      "\n",
      "    accuracy                           0.75     30000\n",
      "   macro avg       0.76      0.75      0.75     30000\n",
      "weighted avg       0.76      0.75      0.75     30000\n",
      "\n",
      "0.7544940315487917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build rf model\n",
    "rf_model = RandomForestClassifier(max_depth=50, n_estimators=80).fit(X_train, y_train) \n",
    "# making predictions\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, rf_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic + Fuzzy + Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>395648</td>\n",
       "      <td>494699</td>\n",
       "      <td>528639</td>\n",
       "      <td>does crow see from just one eye</td>\n",
       "      <td>how far can one see with the naked eye how is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "      <td>0.400244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>25054</td>\n",
       "      <td>46729</td>\n",
       "      <td>46730</td>\n",
       "      <td>how do i unblock fortiguard application control</td>\n",
       "      <td>how can i unblock torrents</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "      <td>0.622001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>44749</td>\n",
       "      <td>80277</td>\n",
       "      <td>80278</td>\n",
       "      <td>how can i make money off bitcoin</td>\n",
       "      <td>can you make money with bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>28223</td>\n",
       "      <td>52353</td>\n",
       "      <td>52354</td>\n",
       "      <td>who is the head of immigration officer of mala...</td>\n",
       "      <td>how do avascular plants and vascular plants di...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "      <td>-0.040175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>306380</td>\n",
       "      <td>429895</td>\n",
       "      <td>429896</td>\n",
       "      <td>what is ionizing radiation</td>\n",
       "      <td>can you feel ionizing radiation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "      <td>0.713251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "395627  395648  494699  528639   \n",
       "25052    25054   46729   46730   \n",
       "44746    44749   80277   80278   \n",
       "28221    28223   52353   52354   \n",
       "306360  306380  429895  429896   \n",
       "\n",
       "                                                question1  \\\n",
       "395627                    does crow see from just one eye   \n",
       "25052     how do i unblock fortiguard application control   \n",
       "44746                    how can i make money off bitcoin   \n",
       "28221   who is the head of immigration officer of mala...   \n",
       "306360                         what is ionizing radiation   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "395627  how far can one see with the naked eye how is ...             0   \n",
       "25052                          how can i unblock torrents             0   \n",
       "44746                     can you make money with bitcoin             0   \n",
       "28221   how do avascular plants and vascular plants di...             0   \n",
       "306360                    can you feel ionizing radiation             0   \n",
       "\n",
       "             wmd  norm_wmd  w2v_cosine  w2v_Manhattan       SIF  \n",
       "395627  0.656735  0.656735    0.007304      -1.356412  0.400244  \n",
       "25052   0.899362  0.899362    0.112670      -2.680161  0.622001  \n",
       "44746   0.000000  0.000000    0.272492       0.382274  0.594603  \n",
       "28221   1.360078  1.360078    0.011833      -1.791117 -0.040175  \n",
       "306360  0.455592  0.455592    0.982493      -0.249461  0.713251  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  data set with similarity measures\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "      <th>SIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395627</td>\n",
       "      <td>395648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "      <td>0.400244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25052</td>\n",
       "      <td>25054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "      <td>0.622001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44746</td>\n",
       "      <td>44749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28221</td>\n",
       "      <td>28223</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>1.360078</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>-1.791117</td>\n",
       "      <td>-0.040175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306360</td>\n",
       "      <td>306380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.455592</td>\n",
       "      <td>0.982493</td>\n",
       "      <td>-0.249461</td>\n",
       "      <td>0.713251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_duplicate       wmd  norm_wmd  w2v_cosine  w2v_Manhattan  \\\n",
       "395627  395648             0  0.656735  0.656735    0.007304      -1.356412   \n",
       "25052    25054             0  0.899362  0.899362    0.112670      -2.680161   \n",
       "44746    44749             0  0.000000  0.000000    0.272492       0.382274   \n",
       "28221    28223             0  1.360078  1.360078    0.011833      -1.791117   \n",
       "306360  306380             0  0.455592  0.455592    0.982493      -0.249461   \n",
       "\n",
       "             SIF  \n",
       "395627  0.400244  \n",
       "25052   0.622001  \n",
       "44746   0.594603  \n",
       "28221  -0.040175  \n",
       "306360  0.713251  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl = df.drop(['question1', 'question2', 'qid1', 'qid2'], axis=1)\n",
    "df_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"masters/df_basic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>num_words_q1</th>\n",
       "      <th>num_words_q2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_min</th>\n",
       "      <th>ct_max</th>\n",
       "      <th>token_len_abs</th>\n",
       "      <th>token_len_avg</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>395627</td>\n",
       "      <td>395648</td>\n",
       "      <td>494699</td>\n",
       "      <td>528639</td>\n",
       "      <td>does crow see from just one eye</td>\n",
       "      <td>how far can one see with the naked eye how is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25052</td>\n",
       "      <td>25054</td>\n",
       "      <td>46729</td>\n",
       "      <td>46730</td>\n",
       "      <td>how do i unblock fortiguard application control</td>\n",
       "      <td>how can i unblock torrents</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44746</td>\n",
       "      <td>44749</td>\n",
       "      <td>80277</td>\n",
       "      <td>80278</td>\n",
       "      <td>how can i make money off bitcoin</td>\n",
       "      <td>can you make money with bitcoin</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28221</td>\n",
       "      <td>28223</td>\n",
       "      <td>52353</td>\n",
       "      <td>52354</td>\n",
       "      <td>who is the head of immigration officer of mala...</td>\n",
       "      <td>how do avascular plants and vascular plants di...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>306360</td>\n",
       "      <td>306380</td>\n",
       "      <td>429895</td>\n",
       "      <td>429896</td>\n",
       "      <td>what is ionizing radiation</td>\n",
       "      <td>can you feel ionizing radiation</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id    qid1    qid2  \\\n",
       "0      395627  395648  494699  528639   \n",
       "1       25052   25054   46729   46730   \n",
       "2       44746   44749   80277   80278   \n",
       "3       28221   28223   52353   52354   \n",
       "4      306360  306380  429895  429896   \n",
       "\n",
       "                                           question1  \\\n",
       "0                   does crow see from just one eye    \n",
       "1   how do i unblock fortiguard application control    \n",
       "2                  how can i make money off bitcoin    \n",
       "3  who is the head of immigration officer of mala...   \n",
       "4                        what is ionizing radiation    \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  how far can one see with the naked eye how is ...             0   \n",
       "1                        how can i unblock torrents              0   \n",
       "2                   can you make money with bitcoin              0   \n",
       "3  how do avascular plants and vascular plants di...             0   \n",
       "4                   can you feel ionizing radiation              0   \n",
       "\n",
       "   num_words_q1  num_words_q2  len_q1  ...    ct_min    ct_max  token_len_abs  \\\n",
       "0             8            14      32  ...  0.428571  0.230769            6.0   \n",
       "1             8             6      48  ...  0.600000  0.428571            2.0   \n",
       "2             8             7      33  ...  0.666667  0.571429            1.0   \n",
       "3            10             9      51  ...  0.000000  0.000000            1.0   \n",
       "4             5             6      27  ...  0.500000  0.400000            1.0   \n",
       "\n",
       "   token_len_avg  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0           10.0          40                  56   \n",
       "1            6.0          56                  67   \n",
       "2            6.5          77                  82   \n",
       "3            8.5          37                  37   \n",
       "4            4.5          75                  78   \n",
       "\n",
       "   fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  \\\n",
       "0                           100                             52   \n",
       "1                           100                             58   \n",
       "2                           100                             77   \n",
       "3                            37                             32   \n",
       "4                           100                             79   \n",
       "\n",
       "   fuzz_token_set_ratio  fuzz_token_sort_ratio  \n",
       "0                    52                     43  \n",
       "1                    67                     49  \n",
       "2                    86                     76  \n",
       "3                    36                     32  \n",
       "4                    82                     67  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data set with basic and fuzzy features\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_words_q1</th>\n",
       "      <th>num_words_q2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cw_min</th>\n",
       "      <th>cw_max</th>\n",
       "      <th>cs_min</th>\n",
       "      <th>cs_max</th>\n",
       "      <th>ct_min</th>\n",
       "      <th>ct_max</th>\n",
       "      <th>token_len_abs</th>\n",
       "      <th>token_len_avg</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>395648</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25054</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44749</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28223</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>306380</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  num_words_q1  num_words_q2  len_q1  len_q2  word_share  cw_min  \\\n",
       "0  395648             8            14      32      62    0.190476    0.75   \n",
       "1   25054             8             6      48      27    0.285714    0.50   \n",
       "2   44749             8             7      33      32    0.333333    1.00   \n",
       "3   28223            10             9      51      51    0.058824    0.00   \n",
       "4  306380             5             6      27      32    0.272727    1.00   \n",
       "\n",
       "     cw_max    cs_min    cs_max    ct_min    ct_max  token_len_abs  \\\n",
       "0  0.500000  0.000000  0.000000  0.428571  0.230769            6.0   \n",
       "1  0.250000  0.666667  0.666667  0.600000  0.428571            2.0   \n",
       "2  1.000000  0.333333  0.250000  0.666667  0.571429            1.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000            1.0   \n",
       "4  0.666667  0.000000  0.000000  0.500000  0.400000            1.0   \n",
       "\n",
       "   token_len_avg  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0           10.0          40                  56   \n",
       "1            6.0          56                  67   \n",
       "2            6.5          77                  82   \n",
       "3            8.5          37                  37   \n",
       "4            4.5          75                  78   \n",
       "\n",
       "   fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  \\\n",
       "0                           100                             52   \n",
       "1                           100                             58   \n",
       "2                           100                             77   \n",
       "3                            37                             32   \n",
       "4                           100                             79   \n",
       "\n",
       "   fuzz_token_set_ratio  fuzz_token_sort_ratio  \n",
       "0                    52                     43  \n",
       "1                    67                     49  \n",
       "2                    86                     76  \n",
       "3                    36                     32  \n",
       "4                    82                     67  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_cl = df2.drop(['question1', 'question2', 'qid1', 'qid2', 'Unnamed: 0','is_duplicate'], axis=1)\n",
    "df2_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  merging two data sets to get total set of features\n",
    "df_total = pd.merge(df_cl,df2_cl, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>w2v_cosine</th>\n",
       "      <th>w2v_Manhattan</th>\n",
       "      <th>SIF</th>\n",
       "      <th>num_words_q1</th>\n",
       "      <th>num_words_q2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_min</th>\n",
       "      <th>ct_max</th>\n",
       "      <th>token_len_abs</th>\n",
       "      <th>token_len_avg</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>395648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.656735</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>-1.356412</td>\n",
       "      <td>0.400244</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.899362</td>\n",
       "      <td>0.112670</td>\n",
       "      <td>-2.680161</td>\n",
       "      <td>0.622001</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272492</td>\n",
       "      <td>0.382274</td>\n",
       "      <td>0.594603</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  is_duplicate       wmd  norm_wmd  w2v_cosine  w2v_Manhattan  \\\n",
       "0  395648             0  0.656735  0.656735    0.007304      -1.356412   \n",
       "1   25054             0  0.899362  0.899362    0.112670      -2.680161   \n",
       "2   44749             0  0.000000  0.000000    0.272492       0.382274   \n",
       "3   44749             0  0.000000  0.000000    0.272492       0.382274   \n",
       "4   44749             0  0.000000  0.000000    0.272492       0.382274   \n",
       "\n",
       "        SIF  num_words_q1  num_words_q2  len_q1  ...    ct_min    ct_max  \\\n",
       "0  0.400244             8            14      32  ...  0.428571  0.230769   \n",
       "1  0.622001             8             6      48  ...  0.600000  0.428571   \n",
       "2  0.594603             8             7      33  ...  0.666667  0.571429   \n",
       "3  0.594603             8             7      33  ...  0.666667  0.571429   \n",
       "4  0.594603             8             7      33  ...  0.666667  0.571429   \n",
       "\n",
       "   token_len_abs  token_len_avg  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0            6.0           10.0          40                  56   \n",
       "1            2.0            6.0          56                  67   \n",
       "2            1.0            6.5          77                  82   \n",
       "3            1.0            6.5          77                  82   \n",
       "4            1.0            6.5          77                  82   \n",
       "\n",
       "   fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  \\\n",
       "0                           100                             52   \n",
       "1                           100                             58   \n",
       "2                           100                             77   \n",
       "3                           100                             77   \n",
       "4                           100                             77   \n",
       "\n",
       "   fuzz_token_set_ratio  fuzz_token_sort_ratio  \n",
       "0                    52                     43  \n",
       "1                    67                     49  \n",
       "2                    86                     76  \n",
       "3                    86                     76  \n",
       "4                    86                     76  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126556, 26)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87862, 26)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87862 entries, 0 to 126555\n",
      "Data columns (total 26 columns):\n",
      "id                               87862 non-null int64\n",
      "is_duplicate                     87862 non-null int64\n",
      "wmd                              87862 non-null float64\n",
      "norm_wmd                         87862 non-null float64\n",
      "w2v_cosine                       87862 non-null float64\n",
      "w2v_Manhattan                    87862 non-null float64\n",
      "SIF                              87862 non-null float64\n",
      "num_words_q1                     87862 non-null int64\n",
      "num_words_q2                     87862 non-null int64\n",
      "len_q1                           87862 non-null int64\n",
      "len_q2                           87862 non-null int64\n",
      "word_share                       87862 non-null float64\n",
      "cw_min                           87862 non-null float64\n",
      "cw_max                           87862 non-null float64\n",
      "cs_min                           87862 non-null float64\n",
      "cs_max                           87862 non-null float64\n",
      "ct_min                           87862 non-null float64\n",
      "ct_max                           87862 non-null float64\n",
      "token_len_abs                    87862 non-null float64\n",
      "token_len_avg                    87862 non-null float64\n",
      "fuzz_ratio                       87862 non-null int64\n",
      "fuzz_partial_ratio               87862 non-null int64\n",
      "fuzz_partial_token_set_ratio     87862 non-null int64\n",
      "fuzz_partial_token_sort_ratio    87862 non-null int64\n",
      "fuzz_token_set_ratio             87862 non-null int64\n",
      "fuzz_token_sort_ratio            87862 non-null int64\n",
      "dtypes: float64(14), int64(12)\n",
      "memory usage: 18.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_total.head()\n",
    "df_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.5156496431068404\n",
      "XGBoost 0.7579630261938441\n",
      "RandomForest 0.7605970440466319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import scipy \n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "df_total = df_total.fillna(df_sim.median()).clip(-1e11,1e11)\n",
    "\n",
    "X = df_total.drop(['is_duplicate'],axis=1)\n",
    "y = df_total['is_duplicate']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y , test_size = 0.3, random_state = 123)\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append((\"LogisticRegression\",LogisticRegression()))\n",
    "models.append((\"XGBoost\", xgb.XGBClassifier()))\n",
    "models.append((\"RandomForest\",RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name,model in models:\n",
    "    result = cross_val_score(model, X_train, y_train,  cv=3)\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(names[i],results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75     13771\n",
      "           1       0.71      0.83      0.77     12588\n",
      "\n",
      "    accuracy                           0.76     26359\n",
      "   macro avg       0.77      0.76      0.76     26359\n",
      "weighted avg       0.77      0.76      0.76     26359\n",
      "\n",
      "0.7626483112010319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build XGboost model\n",
    "xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train) \n",
    "# making predictions\n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, xgb_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75     13771\n",
      "           1       0.71      0.83      0.77     12588\n",
      "\n",
      "    accuracy                           0.76     26359\n",
      "   macro avg       0.77      0.76      0.76     26359\n",
      "weighted avg       0.77      0.76      0.76     26359\n",
      "\n",
      "0.7634663385062169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# build rf model\n",
    "rf_model = RandomForestClassifier(max_depth=50, n_estimators=80).fit(X_train, y_train) \n",
    "# making predictions\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "\n",
    "# performance assessment\n",
    "print(classification_report(y_test, rf_prediction))\n",
    "\n",
    "print(roc_auc_score(y_test, rf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
